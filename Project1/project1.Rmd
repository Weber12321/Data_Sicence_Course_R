---
title: "Project1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project1 : TFIDF練習-以聯合報柯文哲新聞為例

練習TFIDF，以爬取**聯合報新聞**內容關鍵字柯文哲，為練習對象。
由於2018資料量過大，詞頻分析僅以**五月**資料組當作內容。

## 匯入套件
```{r pack}
# ===== personal project01
# ===== 處理聯合報柯文哲1月至5月的文章
# 製作tfidf(以五月為例)
# ------------------------------------------
# 匯入套件
library(tibble)
library(dplyr)
library(tidyr)
library(stats)
library(proxy)
library(readtext)
library(data.table)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(magrittr)
library(slam)
library(Matrix)
library(tidytext)
```


## 資料清理
將所有資料bind一起，切開時間變數為年、月、日與時間，刪除遺漏、重複資訊。
分割整理後資料為各五個月小資料組
```{r dataCleaning}
# 資料清理 
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/Weber1234/Project1")
Ko_data <- read.csv("ko_Output.csv")
Ko_data2 <- read.csv("ko_Output2.csv")
# 整合需要的欄位
all <- rbind(Ko_data[,3:5], Ko_data2[,2:4])
# 清除NA
all <- all %>% na.omit()
# 切開時間
all <- all %>% separate(V2, c("year","month","day"),"-")
all <- all %>% separate(day, c("date","time"), " ")
all <- all[with(all, order(year, month, date)), ]
# 移除重複資料
all <- all[!duplicated(all$bindtext), ]
row.names(all) = c(1:3112) # 由資料數重新編排號碼
# 個月份資料分割
ko1<- subset(all, all$month == "01", select = month)
ko2<- subset(all, all$month == "02", select = month)
ko3<- subset(all, all$month == "03", select = month)
ko4<- subset(all, all$month == "04", select = month)
ko5<- subset(all, all$month == "05", select = month)
# use may data for tfidf
New <- subset(all, all$month == "05", select = c(month, date, V1, bindtext))

# -----------------------------
# 匯出清理完資料
# Media <- c()
# text <- c("UDN")
# for( i in 1:length(Ko$bindtext)){
  # Media <- rbind(Media, text)
# }
# Ko <- cbind(Media, Ko)
# write.table(Ko , file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/NewsCleaning/Ko_udn.csv", sep = ",")
# -----------------------------

```

## 文字切詞
以5月資料組為處理對象，刪除文章內符號與雜訊，加入自訂字典，建立TF與DF
```{r corpus }
# ==== 切詞
# cor_word <- function(data){}
docs <- Corpus(VectorSource(New$bindtext))
toSpace <- content_transformer(function(x,pattern){
  return(gsub(pattern," ",x))
})
# 刪去單詞贅字、英文字母、標點符號、數字與空格
docs <- tm_map(docs,toSpace,"\n")
clean_doc <- function(docs){
  clean_words <- c("[A-Za-z0-9]","、","《","『","』","【","】","／","，","。","！","「","（","」","）","\n","；",">","<","＜","＞")
  for(i in 1:length(clean_words)){
    docs <- tm_map(docs,toSpace, clean_words[i])
  }
  return(docs)
}
docs <- clean_doc(docs)
clean_word_doc <- function(docs){
  clean_words <- c("分享","記者","攝影","提及","表示","報導","我們","他們","的","也","都","就","與","但","是","在","和","及","為","或","且","有","含")
  for(i in 1:length(clean_words)){
    docs <- tm_map(docs,toSpace, clean_words[i])
  }
  return(docs)
}
docs <- clean_word_doc(docs)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removePunctuation)
# 匯入自定義字典
mixseg = worker()
segment <- c("柯文哲","姚文智","丁守中","台北市長","選舉","候選人","台灣","選票","柯市長","民進黨","國民黨","台北市民","市民")
new_user_word(mixseg,segment)

# 有詞頻之後就可以去畫文字雲
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))

d.corpus <- Corpus(VectorSource(seg))
tdm <- TermDocumentMatrix(d.corpus)
tf <- as.matrix(tdm)
DF <- tidy(tf)
```

## TFIDF
```{r TFIDF}
# tf-idf
N = tdm$ncol
tf <- apply(tdm, 2, sum)
idfCal <- function(word_doc)
{ 
  log2( N / nnzero(word_doc) ) 
}
idf <- apply(tdm, 1, idfCal)

doc.tfidf <- as.matrix(tdm)

for(x in 1:nrow(tdm)){
  for(y in 1:ncol(tdm))
  {
    doc.tfidf[x,y] <- (doc.tfidf[x,y] / tf[y]) * idf[x]
  }
}

findZeroId = as.matrix(apply(doc.tfidf, 1, sum))
tfidfnn = doc.tfidf
```

## 資料視覺化
1. plot今年各月份，柯文哲的文章數量，以觀變化
2. plot TFIDF 看五月份用詞頻率
```{r visualization}
# 視覺化
# 每月文章數
post <- data.frame(c(1:5))
mon <- c(nrow(ko1),nrow(ko2),nrow(ko3),nrow(ko4),nrow(ko5))
post <- cbind(post, mon)
names(post) <- c("month", "NewsNum")  
library(ggplot2)
ggplot(post, aes(month, NewsNum)) +
  geom_bar(stat="identity", fill = "green") + 
  xlab("月份") + ylab("新聞數") +
  ggtitle("2018柯文哲聯合報新聞量")

# plot tfidf
freq=rowSums(as.matrix(tfidfnn))
head(freq,10)
tail(freq,10)
plot(sort(freq, decreasing = T),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
high.freq=tail(sort(freq),n=10)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df) 

ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
  geom_bar(stat="identity", fill = "red") + coord_flip() + 
  xlab("詞彙") + ylab("頻率") +
  ggtitle("Term frequencies")
```

## 結論
1. 詞頻出現英文不知是不是編碼問題，切詞應該去除所有的英文符號??
2. DF、TF、TFIDF都無法用head()顯示內容，推測可能資料量過大??

